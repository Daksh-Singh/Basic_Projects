{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Save, Load and Export Keras Models - Completed.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r57fDKSPzBWN",
        "colab_type": "code",
        "colab": {},
        "outputId": "f288e897-ed9a-41f6-811d-42bb9ad27164"
      },
      "source": [
        "#importing thre required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#to check the version of tensorflow\n",
        "print('This notebook works with TensorFlow version:', tf.__version__)\n",
        "#creating some folders which will be required later on\n",
        "folders = ['tmp', 'models', 'model_name', 'weights']\n",
        "for folder in folders:\n",
        "    if not os.path.isdir(folder):\n",
        "        os.mkdir(folder)\n",
        "\n",
        "print(os.listdir('.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This notebook works with TensorFlow version: 2.0.1\n",
            "['.ipynb_checkpoints', 'models', 'model_name', 'Save, Load and Export Keras Models - Completed.ipynb', 'Student Notebook.ipynb', 'tmp', 'weights']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP5DSVxRzBWy",
        "colab_type": "code",
        "colab": {},
        "outputId": "6c8db6cc-2c10-4979-8a5d-b969e649ce53"
      },
      "source": [
        "#we will create a model that will be trained on the Fashion MNIST dataset\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfLTn4KbzBXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the data \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "#preprocessing the data\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
        "\n",
        "#one hot encoding the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxdmJnqizBXf",
        "colab_type": "code",
        "colab": {},
        "outputId": "226ec362-bd97-4e01-aa34-86d889b8cb56"
      },
      "source": [
        "checkpoint_dir = 'weights/'\n",
        "#to save the weights of the model during training\n",
        "#training the model\n",
        "\n",
        "_ = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=2,\n",
        "    batch_size=512,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            os.path.join(checkpoint_dir, 'epoch_{epoch:02d}_acc_{val_acc:.4f}'),\n",
        "            monitor='val_acc', save_weights_only=True, save_best_only=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.6875 - acc: 0.7692 - val_loss: 0.4884 - val_acc: 0.8312\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4349 - acc: 0.8486 - val_loss: 0.4453 - val_acc: 0.8409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXfET0IOzBXt",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7dbca20-b5b8-4618-cfc5-1e656cd70d61"
      },
      "source": [
        "os.listdir(checkpoint_dir)\n",
        "#to check the files in the directories"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint',\n",
              " 'epoch_01_acc_0.8312.data-00000-of-00001',\n",
              " 'epoch_01_acc_0.8312.index',\n",
              " 'epoch_02_acc_0.8409.data-00000-of-00001',\n",
              " 'epoch_02_acc_0.8409.index']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lOvsoTQzBX_",
        "colab_type": "code",
        "colab": {},
        "outputId": "79fddbfe-72f2-4fc4-de85-1c682d86a0d6"
      },
      "source": [
        "#creating the model\n",
        "model = create_model()\n",
        "#it has randomized weights\n",
        "#evaluating the model on the test data\n",
        "print(model.evaluate(x_test, y_test, verbose=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3682680805206298, 0.1051]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_tlm1HyzBYM",
        "colab_type": "code",
        "colab": {},
        "outputId": "57fb7939-ff19-4311-db83-61c09358a4b9"
      },
      "source": [
        "#loading the save weights\n",
        "model.load_weights('weights/epoch_02_acc_0.8409')\n",
        "print(model.evaluate(x_test, y_test, verbose=False))\n",
        "#it is using the trained and save weights not the random weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4453496052503586, 0.8409]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69H38kVJzBYW",
        "colab_type": "code",
        "colab": {},
        "outputId": "d98c8676-d56c-4e2e-8e46-b2befb78d5c8"
      },
      "source": [
        "models_dir = 'models/'\n",
        "#saving the complete model, means weights as well as complete archtitecture\n",
        "model = create_model()\n",
        "\n",
        "_ = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=2,\n",
        "    batch_size=512,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            os.path.join(models_dir, 'epoch_{epoch:02d}_acc_{val_acc:.4f}.h5'),\n",
        "            monitor='val_acc', save_weights_only=False, save_best_only=False\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.6814 - acc: 0.7665 - val_loss: 0.4801 - val_acc: 0.8310\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.4300 - acc: 0.8498 - val_loss: 0.4398 - val_acc: 0.8434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkUsez0_zBYl",
        "colab_type": "code",
        "colab": {},
        "outputId": "98150b5c-0cea-4089-b7f1-e47fa07828b1"
      },
      "source": [
        "os.listdir(models_dir)\n",
        "#to check the content of the directory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['epoch_01_acc_0.8310.h5', 'epoch_02_acc_0.8434.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU8L3V1-zBYz",
        "colab_type": "code",
        "colab": {},
        "outputId": "5dcccf04-2877-438b-8153-c8196f3f568e"
      },
      "source": [
        "model = create_model()\n",
        "#loading the model with the random weights\n",
        "print(model.evaluate(x_test, y_test, verbose=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3553888145446775, 0.1222]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFljYi1CzBZA",
        "colab_type": "code",
        "colab": {},
        "outputId": "64244afd-cc64-4966-d1a6-0fcce69d9a35"
      },
      "source": [
        "model = tf.keras.models.load_model('models/epoch_02_acc_0.8434.h5')\n",
        "#laoding the saved model and weights\n",
        "model.summary()\n",
        "#to check the model architetcure\n",
        "print(model.evaluate(x_test, y_test, verbose=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[0.43983762526512143, 0.8434]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usn3dTbvzBZQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "927c71ff-9f98-47b2-b975-5ca579f08d67"
      },
      "source": [
        "#saving the weights mannually\n",
        "model.save_weights('tmp/manually_saved')\n",
        "print(os.listdir('tmp'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['checkpoint', 'manually_saved.data-00000-of-00001', 'manually_saved.index']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiLqKPXHzBZX",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4d57bae-a37d-4f01-e3d1-55cf4c2a1576"
      },
      "source": [
        "#saving the model architecture mannualy\n",
        "model.save('tmp/manually_saved_model.h5')\n",
        "print(os.listdir('tmp'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['checkpoint', 'manually_saved.data-00000-of-00001', 'manually_saved.index', 'manually_saved_model.h5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkKiwkiZzBZi",
        "colab_type": "code",
        "colab": {},
        "outputId": "57177699-3dc1-4100-923c-2fc0b2598436"
      },
      "source": [
        "#saving the model with the help of tensorflow\n",
        "model.save('model_name')\n",
        "#path of the directory where the model is needed to be saved\n",
        "print(os.listdir('model_name'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 14:26:48.389150  2576 deprecation.py:506] From c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['assets', 'saved_model.pb', 'variables']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaZazyvRzBZr",
        "colab_type": "code",
        "colab": {},
        "outputId": "613945ad-b909-4e9d-8e1b-5c844fe1829c"
      },
      "source": [
        "#Loading the saved model file\n",
        "model = tf.keras.models.load_model('model_name')\n",
        "#giving the directory name where the model is saved\n",
        "print(model.evaluate(x_test, y_test, verbose=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4398376216888428, 0.8434]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}