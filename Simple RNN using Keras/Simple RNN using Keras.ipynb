{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple RNN using Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bAt8hYwroRr",
        "colab_type": "text"
      },
      "source": [
        "### Making Your Model Learn Addition!\n",
        "\n",
        "Given the string \"54+7\", the model should return a prediction: \"61\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsX7wY65roR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the required libraries\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import TimeDistributed, Dense, Dropout, SimpleRNN, RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
        "\n",
        "from termcolor import colored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hP-OyQrivBNl",
        "colab": {}
      },
      "source": [
        "all_chars = '0123456789+'\n",
        "#list of all the possible characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85144Qm9roTU",
        "colab_type": "code",
        "colab": {},
        "outputId": "de3c8250-1802-41cc-f33d-1ed070bff5a0"
      },
      "source": [
        "#dimension for the one hot encoding of characters\n",
        "num_features = len(all_chars)\n",
        "\n",
        "#to tokenize the character to numeric values\n",
        "char_to_index = dict((c, i) for i, c in enumerate(all_chars))\n",
        "#to inverse the above dictionary\n",
        "index_to_char = dict((i, c) for i, c in enumerate(all_chars))\n",
        "\n",
        "print('Number of features:', num_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2b1Xg9hvBNr",
        "colab": {},
        "outputId": "756da8c6-0d69-44ba-ed17-9a05a0dd5f0b"
      },
      "source": [
        "#function to create a single example and label pair\n",
        "def generate_data():\n",
        "    first_num = np.random.randint(low=0,high=100)\n",
        "    second_num = np.random.randint(low=0,high=100)\n",
        "    example = str(first_num) + '+' + str(second_num)\n",
        "    label = str(first_num+second_num)\n",
        "    return example, label\n",
        "#to check the function working\n",
        "generate_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('93+31', '124')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Ezwwo-roUM",
        "colab_type": "text"
      },
      "source": [
        "Since to understand the reviews properly where the word came in sentence is also important along with the word.\n",
        "\n",
        "Consider these two reviews:\n",
        "\n",
        "Review 1: This movie is not terrible at all.\n",
        "\n",
        "Review 2: This movie is pretty decent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZKl0LtdvBNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "34a3c344-5985-4e3b-e1ac-392c18739308"
      },
      "source": [
        "#creation of simple RNN model\n",
        "hidden_units = 128\n",
        "max_time_steps = 5\n",
        "#maximum length of the input expression\n",
        "\n",
        "#we will use simple RNN layer\n",
        "#encoder is the simple RNN layer\n",
        "#to acheive the single vector representation of the entire input we will use repeat vector\n",
        "#now decoder will contain another simple RNN layer which will return the sequence\n",
        "#so that model understands that the hidden layer will vary according to the time stamps so we will add the dense layer in the time distriuted \n",
        "model = Sequential([\n",
        "    SimpleRNN(hidden_units, input_shape=(None, num_features)),\n",
        "    RepeatVector(max_time_steps),\n",
        "    SimpleRNN(hidden_units, return_sequences=True),\n",
        "    TimeDistributed(Dense(num_features, activation='softmax'))\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               17920     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 5, 128)            32896     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 5, 11)             1419      \n",
            "=================================================================\n",
            "Total params: 52,235\n",
            "Trainable params: 52,235\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ci29YaA6vBN1",
        "colab": {},
        "outputId": "3013716f-5845-4add-f272-e2eab2946151"
      },
      "source": [
        "#Function to vectorize the examples and labels\n",
        "def vectorize_example(example, label):\n",
        "    \n",
        "    #placeholder for the example and labels, and we will make them of same length\n",
        "    x = np.zeros((max_time_steps, num_features))\n",
        "    y = np.zeros((max_time_steps, num_features))\n",
        "    \n",
        "    #to check how much extra zeros added\n",
        "    diff_x = max_time_steps - len(example)\n",
        "    diff_y = max_time_steps - len(label)\n",
        "    \n",
        "    #doing the one hot encoding\n",
        "    for i, c in enumerate(example):\n",
        "        x[diff_x+i, char_to_index[c]] = 1\n",
        "    #for the padding at the begining\n",
        "    for i in range(diff_x):\n",
        "        x[i, char_to_index['0']] = 1\n",
        "    #same process for the labels\n",
        "    for i, c in enumerate(label):\n",
        "        y[diff_y+i, char_to_index[c]] = 1\n",
        "    for i in range(diff_y):\n",
        "        y[i, char_to_index['0']] = 1\n",
        "        \n",
        "    return x, y\n",
        "\n",
        "#to check the vectorizer function\n",
        "e, l = generate_data()\n",
        "print('Text Example and Label:', e, l)\n",
        "x, y = vectorize_example(e, l)\n",
        "#shape of the vectorized example\n",
        "print('Vectorized Example and Label Shapes:', x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Example and Label: 29+60 89\n",
            "Vectorized Example and Label Shapes: (5, 11) (5, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nARKq-bvBN9",
        "colab": {},
        "outputId": "11bea916-2cf0-4a51-8f16-5eef7767be8d"
      },
      "source": [
        "#devectorization of the examples, that is reverse of the above process\n",
        "def devectorize_example(example):\n",
        "    result = [index_to_char[np.argmax(vec)] for i, vec in enumerate(example)]\n",
        "    return ''.join(result)\n",
        "#we will use the index_to char dictionary for the process to get back the normal example\n",
        "#checking the function\n",
        "devectorize_example(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'29+60'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KCGUxNwNvBOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a721451a-7f7c-42be-bdf0-0c96381f2eb2"
      },
      "source": [
        "devectorize_example(y)\n",
        "#checking the function on label\n",
        "#it will do additional padding which won't affect the labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00089'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5rdrhiVvBOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "426b3722-78cf-494f-8bbf-1cdf7eab3113"
      },
      "source": [
        "#function to create the dataset\n",
        "def create_dataset(num_examples=2000):\n",
        "    #placeholders for training data and labels\n",
        "    x_train = np.zeros((num_examples, max_time_steps, num_features))\n",
        "    y_train = np.zeros((num_examples, max_time_steps, num_features))\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        e, l = generate_data()\n",
        "        #generating the data\n",
        "        x, y = vectorize_example(e, l)\n",
        "        #vectorizing the generated data\n",
        "        x_train[i] = x\n",
        "        y_train[i] = y\n",
        "    \n",
        "    return x_train, y_train\n",
        "\n",
        "#checking the dataset shape\n",
        "x_train, y_train = create_dataset()\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 5, 11) (2000, 5, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RRwiuwcQvBOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07591064-5c57-4adb-ccf6-c226457d2263"
      },
      "source": [
        "#to check the devectorized of the example\n",
        "devectorize_example(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'61+89'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRUvtd0IvBOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d07ce279-06ba-44c4-de91-0ec4fb551877"
      },
      "source": [
        "#devectorizing the corresponding label\n",
        "devectorize_example(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00150'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S8HWRdiOvBOS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2686
        },
        "outputId": "2365b11f-30e8-48cc-e940-4d3267771fbe"
      },
      "source": [
        "#training of the model\n",
        "#lambda callback for just printing the validation accuracy\n",
        "l_cb = LambdaCallback(\n",
        "    on_epoch_end = lambda e, l: print('{:.2f}'.format(l['val_acc']),end = ' _ ')\n",
        ")\n",
        "#early stopping callback for stopping the training early  using the validation loss\n",
        "es_cb = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "#training of the model\n",
        "model.fit(x_train, y_train, epochs =500, batch_size = 256, validation_split = 0.2,\n",
        "         verbose = False, callbacks = [es_cb, l_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.55 _ 0.60 _ 0.62 _ 0.62 _ 0.62 _ 0.62 _ 0.63 _ 0.63 _ 0.63 _ 0.64 _ 0.64 _ 0.65 _ 0.65 _ 0.65 _ 0.65 _ 0.66 _ 0.66 _ 0.66 _ 0.68 _ 0.67 _ 0.68 _ 0.68 _ 0.70 _ 0.70 _ 0.70 _ 0.71 _ 0.71 _ 0.71 _ 0.72 _ 0.71 _ 0.73 _ 0.73 _ 0.73 _ 0.73 _ 0.74 _ 0.74 _ 0.75 _ 0.75 _ 0.74 _ 0.75 _ 0.76 _ 0.76 _ 0.76 _ 0.75 _ 0.76 _ 0.77 _ 0.77 _ 0.78 _ 0.78 _ 0.78 _ 0.79 _ 0.79 _ 0.80 _ 0.80 _ 0.80 _ 0.80 _ 0.81 _ 0.81 _ 0.82 _ 0.83 _ 0.82 _ 0.83 _ 0.83 _ 0.83 _ 0.83 _ 0.84 _ 0.85 _ 0.85 _ 0.86 _ 0.85 _ 0.86 _ 0.87 _ 0.87 _ 0.87 _ 0.88 _ 0.88 _ 0.88 _ 0.88 _ 0.89 _ 0.88 _ 0.89 _ 0.88 _ 0.89 _ 0.89 _ 0.89 _ 0.90 _ 0.89 _ 0.90 _ 0.90 _ 0.91 _ 0.91 _ 0.91 _ 0.91 _ 0.92 _ 0.91 _ 0.91 _ 0.92 _ 0.91 _ 0.92 _ 0.92 _ 0.92 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.92 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.94 _ 0.93 _ 0.93 _ 0.94 _ 0.93 _ 0.93 _ 0.94 _ 0.94 _ 0.94 _ 0.94 _ 0.95 _ 0.94 _ 0.95 _ 0.95 _ 0.94 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.96 _ 0.95 _ 0.95 _ 0.95 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.95 _ 0.95 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.95 _ 0.96 _ 0.96 _ 0.95 _ 0.95 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.97 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.97 _ "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x26f6c9dbc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tlNtu_9ZvBOY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "82198555-f0e8-4a7a-9125-cc61cf4f4a26"
      },
      "source": [
        "#evaluating the performnace of the model\n",
        "x_test, y_test = create_dataset(10)\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "for i, pred in enumerate(preds):\n",
        "    y = devectorize_example(y_test[i])\n",
        "    y_hat = devectorize_example(pred)\n",
        "    col = 'blue'\n",
        "    if y!= y_hat:\n",
        "        col = 'red'\n",
        "    out = 'Input: '+ devectorize_example(x_test[i]) + ' Out: '+y + ' Pred: ' + y_hat\n",
        "    print(colored(out, col))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mInput: 86+52 Out: 00138 Pred: 00138\u001b[0m\n",
            "\u001b[34mInput: 48+30 Out: 00078 Pred: 00078\u001b[0m\n",
            "\u001b[34mInput: 60+26 Out: 00086 Pred: 00086\u001b[0m\n",
            "\u001b[34mInput: 55+93 Out: 00148 Pred: 00148\u001b[0m\n",
            "\u001b[34mInput: 46+49 Out: 00095 Pred: 00095\u001b[0m\n",
            "\u001b[34mInput: 66+77 Out: 00143 Pred: 00143\u001b[0m\n",
            "\u001b[34mInput: 81+63 Out: 00144 Pred: 00144\u001b[0m\n",
            "\u001b[31mInput: 52+37 Out: 00089 Pred: 00099\u001b[0m\n",
            "\u001b[34mInput: 24+31 Out: 00055 Pred: 00055\u001b[0m\n",
            "\u001b[34mInput: 70+45 Out: 00115 Pred: 00115\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}