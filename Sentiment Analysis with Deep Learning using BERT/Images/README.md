This folder contains some of the images that will help the user to easily understand how BERT works for text data. For a short description of what BERT is I can say, BERT is a large-scale transformer-based Language Model that can be finetuned for a variety of tasks.

Usually BERT is not trained locally be the user, it is fine-tuned since for training it requires lot of Data, Time and Resources mainly Computational Power.
